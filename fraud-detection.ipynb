{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataprep.eda import *\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_pod(x):\n",
    "    if (x.hour > 4) and (x.hour <= 8):\n",
    "        return 'Early Morning'\n",
    "    elif (x.hour > 8) and (x.hour <= 12 ):\n",
    "        return 'Morning'\n",
    "    elif (x.hour > 12) and (x.hour <= 16):\n",
    "        return'Noon'\n",
    "    elif (x.hour > 16) and (x.hour <= 20) :\n",
    "        return 'Eve'\n",
    "    elif (x.hour > 20) and (x.hour <= 24):\n",
    "        return'Night'\n",
    "    elif (x.hour <= 4):\n",
    "        return'Late Night'\n",
    "\n",
    "def create_dummies(data,column,prefix):\n",
    "    dummies = pd.get_dummies(data[column.name],prefix = prefix)\n",
    "    data = pd.concat([data,dummies],axis=1)\n",
    "    data = data.drop(columns=[column.name])\n",
    "    return data\n",
    "\n",
    "def get_frequency(data,column,new_var):\n",
    "    freq = column.value_counts()\n",
    "    freq = pd.DataFrame(freq)\n",
    "    freq[\"name\"] = freq.index\n",
    "    freq.rename(columns = {column.name:new_var, 'name':column.name}, inplace = True)\n",
    "    data = data.merge(freq, on = column.name)\n",
    "    data = data.drop(columns=[column.name])\n",
    "    return data\n",
    "\n",
    "def resamplingDataPrep(X_train, y_train, target_var): \n",
    "    # concatenate our training data back together\n",
    "    resampling = X_train.copy()\n",
    "    resampling[target_var] = y_train.values\n",
    "    # separate minority and majority classes\n",
    "    majority_class = resampling[resampling[target_var]==0]\n",
    "    minority_class = resampling[resampling[target_var]==1]\n",
    "    # Get a class count to understand the class imbalance.\n",
    "    print('majority_class: '+ str(len(majority_class)))\n",
    "    print('minority_class: '+ str(len(minority_class)))\n",
    "    return majority_class, minority_class\n",
    "\n",
    "def upsample_SMOTE(X_train, y_train, target_var, ratio):\n",
    "    \"\"\"Upsamples minority class using SMOTE.\n",
    "    Ratio argument is the percentage of the upsampled minority class in relation\n",
    "    to the majority class. Default is 1.0\n",
    "    \"\"\"\n",
    "    sm = SMOTE(random_state=42, sampling_strategy=ratio)\n",
    "    # sm = SMOTEENN(random_state=42,sampling_strategy=0.3)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    resampling = X_train_sm.copy()\n",
    "    resampling[target_var] = y_train_sm.values\n",
    "    majority_class = resampling[resampling[target_var]==0]\n",
    "    minority_class = resampling[resampling[target_var]==1]\n",
    "    print('majority_class: '+ str(len(majority_class)))\n",
    "    print('minority_class: '+ str(len(minority_class)))\n",
    "\n",
    "    return X_train_sm, y_train_sm\n",
    "\n",
    "\n",
    "def prepare_data(data):\n",
    "    X = data.drop(columns=['isFraud'])\n",
    "    y = data['isFraud']\n",
    "    X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    return X_train,X_test,y_train,y_test\n",
    "    \n",
    "\n",
    "def get_month(x):\n",
    "    return x.month\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = pd.read_excel('data-dictionary.xlsx', index_col=0)\n",
    "data_features = pd.read_csv('transactions_obf.csv')\n",
    "data_labels = pd.read_csv('labels_obf.csv')\n",
    "fraud_transactions = data_labels['eventId'].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features.loc[data_features['eventId'].isin(fraud_transactions) , 'isFraud'] = 1\n",
    "data_features.loc[data_features['eventId'].isin(fraud_transactions) == False , 'isFraud'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of the total 118621 transactions, 117746 are genuine and 875 are fraud.\n"
     ]
    }
   ],
   "source": [
    "counts = data_features['isFraud'].value_counts()\n",
    "print(f'Out of the total {len(data_features)} transactions, {dict(counts).get(0)} are genuine and {dict(counts).get(1)} are fraud.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Visualisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transaction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction time has a very high cardinality with 99.6% unique values. It should not be used to train the model as it does not provide much information ot the model. Instead I have extracted the hour from the time and created a new feature which signifies the part of the day when the transaction was made. This can be a great feature as the model can spot patterns to identify suspicious behaviour in unusual time of the day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features['transactionTime'] = pd.to_datetime(data_features['transactionTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pod(x):\n",
    "    if (x.hour > 4) and (x.hour <= 8):\n",
    "        return 'Early Morning'\n",
    "    elif (x.hour > 8) and (x.hour <= 12 ):\n",
    "        return 'Morning'\n",
    "    elif (x.hour > 12) and (x.hour <= 16):\n",
    "        return'Noon'\n",
    "    elif (x.hour > 16) and (x.hour <= 20) :\n",
    "        return 'Eve'\n",
    "    elif (x.hour > 20) and (x.hour <= 24):\n",
    "        return'Night'\n",
    "    elif (x.hour <= 4):\n",
    "        return'Late Night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features['transactionTime'] = pd.to_datetime(data_features['transactionTime'])\n",
    "data_features['transactionMonth'] = data_features['transactionTime'].apply(get_month)\n",
    "data_features['transactionTime'] = data_features['transactionTime'].apply(get_pod)\n",
    "data_features = create_dummies(data_features,data_features['transactionTime'],'time')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eventID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to transaction time 'eventId' has a very high cardinality as well with 100% unique values and it should not be used to train the model. Hence we drop this column from our feature set.\n",
    "data_features = data_features.drop(columns=['eventId'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Account Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account Number has just 766 unique values which is 0.6% of the total values. Account number as it is can't be a great predictor as it is just an id and does not provide any information. But instead \n",
    "# the frequency of the account numbers can be calculated and used as a feature. The number of transactions by the same account is definitely a great predictor for fraud detection systems.\n",
    "# High number of transactions from the same account can signal towards a probable fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "rs = RobustScaler()\n",
    "data_features = get_frequency(data_features,data_features.accountNumber,'acc_freq')\n",
    "data_features['acc_freq'] = rs.fit_transform(data_features['acc_freq'].values.reshape(-1,1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merchant Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merchant Id is a unique id of the merchant and has 33327 unique values. It should not be used as it is while training the model because of its very high cardinality. Frequency of the merchant id could be used but there is a high chance that it gets correlated with 'mcc' as similar merchant ids will always have similar mcc.\n",
    "#  Hence we drop this column from our feature set.\n",
    "data_features = data_features.drop(columns=['merchantId'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC represents the merchant category code of the merchant. It specifies the type of goods or services the merchant provides. It has a high cardinality as well and hence we use the frequency of MCC instead of the MCC codes. \n",
    "# The frequency will represent the number of times a specific type of service or goods category appeared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = get_frequency(data_features,data_features['mcc'],'mcc_freq')\n",
    "data_features['mcc_freq'] = rs.fit_transform(data_features['mcc_freq'].values.reshape(-1,1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merchant Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is the country of the merchant who charged for the transaction. It contains 82 different countries. Using label encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_country_freq = pd.DataFrame(data_features.merchantCountry.value_counts())\n",
    "merchant_country_freq[\"mc\"] = merchant_country_freq.index\n",
    "country_list = merchant_country_freq.loc[merchant_country_freq.merchantCountry>100,\"mc\"] # extracting countires whose transaction frequency is more than 100\n",
    "data_features.loc[data_features[\"merchantCountry\"].isin(country_list)==False,\"merchantCountry\"]=\"low_freq_countires\" # marking rest countries as \"low_freq_countries\"\n",
    "data_features = create_dummies(data_features,data_features['merchantCountry'],'mc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchantZip</th>\n",
       "      <th>posEntryMode</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>availableCash</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>transactionMonth</th>\n",
       "      <th>time_Early Morning</th>\n",
       "      <th>time_Eve</th>\n",
       "      <th>time_Late Night</th>\n",
       "      <th>time_Morning</th>\n",
       "      <th>...</th>\n",
       "      <th>mc_292</th>\n",
       "      <th>mc_372</th>\n",
       "      <th>mc_380</th>\n",
       "      <th>mc_442</th>\n",
       "      <th>mc_528</th>\n",
       "      <th>mc_724</th>\n",
       "      <th>mc_756</th>\n",
       "      <th>mc_826</th>\n",
       "      <th>mc_840</th>\n",
       "      <th>mc_low_freq_countires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CR0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.72</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UB11</td>\n",
       "      <td>1</td>\n",
       "      <td>8.45</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CR0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.98</td>\n",
       "      <td>8500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TS17</td>\n",
       "      <td>1</td>\n",
       "      <td>25.22</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UB11</td>\n",
       "      <td>1</td>\n",
       "      <td>8.38</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118616</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>122.91</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118617</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>309.67</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118618</th>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>38.26</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118619</th>\n",
       "      <td>74133</td>\n",
       "      <td>81</td>\n",
       "      <td>1230.04</td>\n",
       "      <td>8500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118620</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>10.49</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118621 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       merchantZip  posEntryMode  transactionAmount  availableCash  isFraud  \\\n",
       "0              CR0             1              10.72           7500      0.0   \n",
       "1             UB11             1               8.45           7500      0.0   \n",
       "2              CR0             1              11.98           8500      0.0   \n",
       "3             TS17             1              25.22           7500      0.0   \n",
       "4             UB11             1               8.38           7500      0.0   \n",
       "...            ...           ...                ...            ...      ...   \n",
       "118616         NaN             1             122.91            500      0.0   \n",
       "118617         NaN             1             309.67           1500      0.0   \n",
       "118618         NaN            90              38.26           1500      0.0   \n",
       "118619       74133            81            1230.04           8500      0.0   \n",
       "118620         NaN             5              10.49           2500      0.0   \n",
       "\n",
       "        transactionMonth  time_Early Morning  time_Eve  time_Late Night  \\\n",
       "0                      1                   0         0                1   \n",
       "1                      1                   0         0                1   \n",
       "2                      1                   0         0                0   \n",
       "3                      1                   0         0                0   \n",
       "4                      1                   0         0                0   \n",
       "...                  ...                 ...       ...              ...   \n",
       "118616                 6                   0         0                0   \n",
       "118617                 7                   0         0                0   \n",
       "118618                12                   0         1                0   \n",
       "118619                 1                   0         0                0   \n",
       "118620                 9                   0         0                0   \n",
       "\n",
       "        time_Morning  ...  mc_292  mc_372  mc_380  mc_442  mc_528  mc_724  \\\n",
       "0                  0  ...       0       0       0       0       0       0   \n",
       "1                  0  ...       0       0       0       0       0       0   \n",
       "2                  0  ...       0       0       0       0       0       0   \n",
       "3                  0  ...       0       0       0       0       0       0   \n",
       "4                  0  ...       0       0       0       0       0       0   \n",
       "...              ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "118616             0  ...       0       0       0       0       0       0   \n",
       "118617             1  ...       0       0       0       0       0       0   \n",
       "118618             0  ...       0       0       0       0       0       0   \n",
       "118619             0  ...       0       0       0       0       0       0   \n",
       "118620             1  ...       0       0       0       0       0       0   \n",
       "\n",
       "        mc_756  mc_826  mc_840  mc_low_freq_countires  \n",
       "0            0       1       0                      0  \n",
       "1            0       1       0                      0  \n",
       "2            0       1       0                      0  \n",
       "3            0       1       0                      0  \n",
       "4            0       1       0                      0  \n",
       "...        ...     ...     ...                    ...  \n",
       "118616       0       0       1                      0  \n",
       "118617       0       0       1                      0  \n",
       "118618       0       0       1                      0  \n",
       "118619       0       1       0                      0  \n",
       "118620       0       0       0                      0  \n",
       "\n",
       "[118621 rows x 29 columns]"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merchant Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of na values for the feature \"merchantZip\" is 23005\n"
     ]
    }
   ],
   "source": [
    "# It is the zip code of the postal address of the merchant. This column cointains 23005 missing values and the best method is to drop the column.\n",
    "print('The number of na values for the feature \"merchantZip\" is', data_features.apply(lambda x : x.isnull().sum()).to_dict().get('merchantZip'))\n",
    "data_features = data_features.drop(columns=['merchantZip'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Entry Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It represents the point of sale entry mode and there are just 10 distinct values hence we should use a one hot encoder. This can be done using the \n",
    "# get_dummies function from pandas.\n",
    "data_features['posEntryMode'].value_counts()\n",
    "data_features = create_dummies(data_features,data_features['posEntryMode'],'pos_mode')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column contains a certain number of negative values which are not veyr high in magnitude. The minimum tranasction amount is \"-0.15\". \n",
    "# We can either reomove these 183 values or make them zero. It wont make a huge difference if I perform any of these two methods\n",
    "# but leaving the negative values as it is can degrade the performance of our classifier. I chose to remove the observations as -ve transaction values don't make sense\n",
    "# and making them zero without any strong reason would not make any sense. As far as the skewness of this feature is concerned, I do not plan to use a parametric model \n",
    "# hence transforming the values according to a specific distribution won't make sense. \n",
    "\n",
    "neg_indexes = data_features[ data_features['transactionAmount'] < 0 ].index\n",
    "data_features.drop(neg_indexes , inplace=True)\n",
    "data_features['transactionAmount'] = rs.fit_transform(data_features['transactionAmount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>availableCash</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>transactionMonth</th>\n",
       "      <th>time_Early Morning</th>\n",
       "      <th>time_Eve</th>\n",
       "      <th>time_Late Night</th>\n",
       "      <th>time_Morning</th>\n",
       "      <th>time_Night</th>\n",
       "      <th>time_Noon</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_mode_0</th>\n",
       "      <th>pos_mode_1</th>\n",
       "      <th>pos_mode_2</th>\n",
       "      <th>pos_mode_5</th>\n",
       "      <th>pos_mode_7</th>\n",
       "      <th>pos_mode_79</th>\n",
       "      <th>pos_mode_80</th>\n",
       "      <th>pos_mode_81</th>\n",
       "      <th>pos_mode_90</th>\n",
       "      <th>pos_mode_91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "      <td>118438.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.816706</td>\n",
       "      <td>6625.103430</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>6.098676</td>\n",
       "      <td>0.150830</td>\n",
       "      <td>0.181378</td>\n",
       "      <td>0.184206</td>\n",
       "      <td>0.169675</td>\n",
       "      <td>0.131267</td>\n",
       "      <td>0.182644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.089051</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.592918</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.301204</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.490472</td>\n",
       "      <td>3411.326979</td>\n",
       "      <td>0.085489</td>\n",
       "      <td>3.573725</td>\n",
       "      <td>0.357885</td>\n",
       "      <td>0.385332</td>\n",
       "      <td>0.387654</td>\n",
       "      <td>0.375349</td>\n",
       "      <td>0.337694</td>\n",
       "      <td>0.386376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.284818</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.491292</td>\n",
       "      <td>0.073140</td>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.458783</td>\n",
       "      <td>0.100229</td>\n",
       "      <td>0.005811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.496702</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.299536</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.700464</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>325.621060</td>\n",
       "      <td>18500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       transactionAmount  availableCash        isFraud  transactionMonth  \\\n",
       "count      118438.000000  118438.000000  118438.000000     118438.000000   \n",
       "mean            0.816706    6625.103430       0.007363          6.098676   \n",
       "std             4.490472    3411.326979       0.085489          3.573725   \n",
       "min            -0.496702     500.000000       0.000000          1.000000   \n",
       "25%            -0.299536    4500.000000       0.000000          3.000000   \n",
       "50%             0.000000    7500.000000       0.000000          6.000000   \n",
       "75%             0.700464    8500.000000       0.000000          9.000000   \n",
       "max           325.621060   18500.000000       1.000000         12.000000   \n",
       "\n",
       "       time_Early Morning       time_Eve  time_Late Night   time_Morning  \\\n",
       "count       118438.000000  118438.000000    118438.000000  118438.000000   \n",
       "mean             0.150830       0.181378         0.184206       0.169675   \n",
       "std              0.357885       0.385332         0.387654       0.375349   \n",
       "min              0.000000       0.000000         0.000000       0.000000   \n",
       "25%              0.000000       0.000000         0.000000       0.000000   \n",
       "50%              0.000000       0.000000         0.000000       0.000000   \n",
       "75%              0.000000       0.000000         0.000000       0.000000   \n",
       "max              1.000000       1.000000         1.000000       1.000000   \n",
       "\n",
       "          time_Night      time_Noon  ...     pos_mode_0     pos_mode_1  \\\n",
       "count  118438.000000  118438.000000  ...  118438.000000  118438.000000   \n",
       "mean        0.131267       0.182644  ...       0.000093       0.089051   \n",
       "std         0.337694       0.386376  ...       0.009637       0.284818   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "50%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "75%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "          pos_mode_2     pos_mode_5     pos_mode_7    pos_mode_79  \\\n",
       "count  118438.000000  118438.000000  118438.000000  118438.000000   \n",
       "mean        0.000135       0.592918       0.005378       0.000262   \n",
       "std         0.011622       0.491292       0.073140       0.016176   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       1.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         pos_mode_80    pos_mode_81    pos_mode_90    pos_mode_91  \n",
       "count  118438.000000  118438.000000  118438.000000  118438.000000  \n",
       "mean        0.000777       0.301204       0.010149       0.000034  \n",
       "std         0.027860       0.458783       0.100229       0.005811  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000       0.000000  \n",
       "75%         0.000000       1.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available Cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column seems to be perfectly fine and can be used in our prediction models as it is. \n",
    "data_features['availableCash'] = rs.fit_transform(data_features['availableCash'].values.reshape(-1,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set balance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only 0.74% transactions that are fraudulent, a classifier that predicts every transaction to be not fraudulent will achieve accuracy score of 99.26%. However, such a classifier is valueless. Therefore, in the cases when classes are imbalanced, metrics other than accuracy should be considered. These metrics include precision, recall and a combination of these two metrics (F2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the target variable \"isFraud\" is highly imbalanced. In such case the classifier will favour the majority classs start generating false predictions.\n",
    "# Hence we upsample the minority class using synthetic monetory upsampling technique. \n",
    "\n",
    "# The penalty for mislabeling a fraud transaction as legitimate is having a user’s money stolen, which the credit card company\n",
    "# typically reimburses. On the other hand, the penalty for mislabeling a legitimate transaction as fraud is having the user frozen\n",
    "# out of their finances and unable to make payments. Balancing the data keeping in mind that we need to catch most of the fraudulent\n",
    "# transactions and have the least number of false positives. I will be using \n",
    "\n",
    "# After reviewing many techniques and the problem statement, I reached to a conclusion that false positives should be minimum and recall at the same time should be \n",
    "# good as well. Hence I did not oversample with 1:1 ratio. More the synthetic samples the model sees, more the recall but also the chance of getting \n",
    "# false positives increases a lot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = prepare_data(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_class: 94052\n",
      "minority_class: 698\n",
      "majority_class: 94052\n",
      "minority_class: 94052\n"
     ]
    }
   ],
   "source": [
    "maj_class, min_class = resamplingDataPrep(X_train,y_train,'isFraud')\n",
    "\n",
    "X_train_sm, y_train_sm = upsample_SMOTE(X_train,y_train,'is_Fraud',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = XGBClassifier()\n",
    "# x.fit(X_train_sm,y_train_sm)\n",
    "# d = x.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(confusion_matrix(y_test,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import argmax\n",
    "# from sklearn.metrics import precision_recall_curve\n",
    "# yhat = x.predict_proba(X_test)\n",
    "# yhat = yhat[:, 1]\n",
    "# precision, recall, thresholds = precision_recall_curve(y_test, yhat)\n",
    "# fscore = (2 * precision * recall) / (precision + recall)\n",
    "# ix = argmax(fscore)\n",
    "# print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "# no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "# plt.plot([0,1], [no_skill,no_skill], linestyle='--', label=f'Baseline score {round(no_skill,3)}')\n",
    "# plt.plot(recall, precision, marker='.', label='XGB')\n",
    "# plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_imp = pd.DataFrame(sorted(zip(logisticRegr.feature_importances_,X.columns)), columns=['Value','Feature'])\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "# plt.title('Random Forest')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.savefig('f-imp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               models  precision_score  recall_score  f1_score    pr_auc\n",
      "0  LogisticRegression         0.049065      0.798851  0.092451  0.040673\n",
      "1        DecisionTree         0.372760      0.597701  0.459161  0.225754\n",
      "2        RandomForest         0.776000      0.557471  0.648829  0.435848\n",
      "3             XGBoost         0.574163      0.689655  0.626632  0.398254\n",
      "4            ADABoost         0.041823      0.833333  0.079648  0.036077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, average_precision_score\n",
    "models = {'LogisticRegression': LogisticRegression(),\n",
    "'DecisionTree':DecisionTreeClassifier(),\n",
    "'RandomForest':RandomForestClassifier(),\n",
    "'XGBoost':XGBClassifier(),\n",
    "'ADABoost': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "f1 = []\n",
    "\n",
    "for u,v in models.items():\n",
    "    b_model = v.fit(X_train_sm,y_train_sm)\n",
    "    preds_b = b_model.predict(X_test)\n",
    "    f1.append([u,precision_score(y_test,preds_b),recall_score(y_test,preds_b),f1_score(y_test,preds_b),average_precision_score(y_test,preds_b)])\n",
    "\n",
    "\n",
    "f1 = pd.DataFrame(f1,columns=['models','precision_score','recall_score','f1_score','pr_auc'])\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test.value_counts()[1]/y_test.value_counts()[0] # baseline pr_auc for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier()\n",
    "# xgb.fit(X_train_sm,y_train_sm)\n",
    "# xgb_pred = xgb.predict(X_test)\n",
    "# print(classification_report(y_test,xgb_pred))\n",
    "# print(confusion_matrix(y_test,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_features.hist(figsize=(50,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = RandomForestClassifier()\n",
    "# lr.fit(X_train,y_train)\n",
    "# p = lr.predict(X_test)\n",
    "# print(classification_report(y_test,p))\n",
    "# print(confusion_matrix(y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example of evaluating a decision tree with random undersampling\n",
    "# from numpy import mean\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from imblearn.pipeline import Pipeline\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# # define pipeline\n",
    "# steps = [('under', RandomUnderSampler()), ('model', RandomForestClassifier())]\n",
    "# pipeline = Pipeline(steps=steps)\n",
    "# # evaluate pipeline\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# scores = cross_val_score(pipeline, X_train, y_train, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "# score = mean(scores)\n",
    "# print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit as sss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "# rfc_model=  imbpipeline(steps = [['smote', SMOTE()],['rfc', RandomForestClassifier()]])\n",
    "\n",
    "# # Choose the grid of hyperparameters we want to use for Grid Search to build our candidate models\n",
    "# rfc_param_grid={\n",
    "#     'rfc__n_estimators': [1,10,100,500],\n",
    "#     'rfc__max_depth': [4, 5, 6]}\n",
    "\n",
    "# stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Create a grid search object which will store the scores and hyperparameters of all candidate models \n",
    "# rfc_param_grid = GridSearchCV(\n",
    "#     rfc_model, \n",
    "#     rfc_param_grid,\n",
    "#     scoring='f1',\n",
    "#     cv=stratified_kfold, verbose=10)\n",
    "\n",
    "# # Fit the models specified by the parameter grid \n",
    "# tqdm(rfc_param_grid.fit(X_train, y_train))\n",
    "\n",
    "# # get the best hyperparameters from grid search object with its best_params_ attribute\n",
    "# print('Best parameters found:\\n', rfc_param_grid.best_params_)\n",
    "\n",
    "# print(rfc_param_grid.best_score_)\n",
    "# rfc_grid_predict = rfc_param_grid.predict(X_val)\n",
    "# print(confusion_matrix(y_val,rfc_grid_predict))\n",
    "# print(classification_report(y_val,rfc_grid_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_f1_pr_auc(x,name,X_test,y_test):\n",
    "    yhat = x.predict_proba(X_test)\n",
    "    yhat = yhat[:, 1]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, yhat)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    ix = argmax(fscore)\n",
    "    print(f'Best Threshold = {thresholds[ix]} and best F-Score {round(fscore[ix],3)} achieved for {name}')\n",
    "    no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "    plt.plot([0,1], [no_skill,no_skill], linestyle='--', label=f'Baseline score {round(no_skill,3)}')\n",
    "    plt.plot(recall, precision, marker='.', label=name)\n",
    "    plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig('figs/pr_auc.png')\n",
    "    return thresholds[ix], fscore[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold = 0.6495132446289062 and best F-Score 0.74 achieved for XGB\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAq30lEQVR4nO3deXxU1f3/8dcnMcgioAIqSjBUsVWBRIgIVbSCCyriz30H1JZv3VBbccNvtVa+tuVRv1bburVslW9FbVUURKnQugDFgKhsClKWAGpADWUnyef3x52ELDPJJJnJZGbez8djHpl7zp07n0uG+eScc+855u6IiEj6ykh0ACIiklhKBCIiaU6JQEQkzSkRiIikOSUCEZE0t1+iA6ivjh07ek5OTqLDEBFJKgsXLtzs7p3C1SVdIsjJyaGgoCDRYYiIJBUzWxupTl1DIiJpTolARCTNKRGIiKQ5JQIRkTSnRCAikubilgjMbLyZfWVmSyLUm5k9bmarzOxjM+sdr1hERCSyeF4+OhH4HTA5Qv05QPfQ4yTgydDP+Fi/ANa8CzkDILvvvu1WHWDnln3lkV4DVfev/LpwdV98BDgcllf1+OsXwEd/qVoXLobq8dX3mOHqcq+KfO7RnEMs6sK9X6zeJ9zvUETqFLdE4O7vmFlOLbtcAEz2YB7s+WZ2oJl1dvdNMQ9m/QKYOARK90BGJhw1ED6fDWUl+/bJ2A96XQ7tjgi2t26Aj6dCWSlYqOHkpTWPbZmR6yrL2C9431VvR963PAYIvXdJ+P2iOWa4uoWT4ehBNc892nOIlXi9336tYPg0JQORekrkDWVHAOsrbReGymokAjMbCYwE6Nq1a/3fac27QRLAgy/AlW/V3KesBBZPASxUUGmdhtq+sKL9Mov0vmFjiFJtxwxX56Xh92+qBBDv9yvdE/yulQhE6iUp7ix292eAZwDy8/Prv5JOzgDYr2XwRZHZAgb/EmbeA6W7wcuADNhv/6p/Ta5fAJOGhloR+1GRRLyMIFl48LrMrAh1lYWOP/iX8MZdwftWqHSs8hgg9N67G3jMCHWZLeCccTXPPapzKC9rbF2494vF+xC03IrXQ8HEhnc3bVocHCvvKiUUSRuJTAQbgOxK211CZbGX3Tf4gq08RnDocbWPEVR/DcRmjODQ46IbIyh/74YeM1xd+RhBuHOP5hya4xjBtq9gxQygDMr2QsGE2HxmFj8HI2YoGUhasHguVRkaI3jd3XuEqTsPuAU4l2CQ+HF3r/N/XX5+vmuuIanw7m/g7YeB6i2LGDhqIBx7gQanJSWY2UJ3zw9XF7cWgZn9BfgB0NHMCoEHgCwAd38KmEGQBFYBO4Dr4hWLpLCcAUE3WK3daA3sbvp8dvCIRIPTkiLiedXQlXXUO3BzvN5f0kTlLrzGdl1tWAgrpkf/3qW7NTgtKSEpBotFapXdNzZfxusXwKrZYVoXEQanvSxIIiJJTolApFyk1kXllsSmj4KWAwAGy18NnmrMQJKYEoFIZXW1LgomVkoEXmkcwYJLlDVmIElIk86J1MfOLREqHEp2hS7VFUkuahGI1EfOgOBqoYpxhMocFk2G3CvDtwqimd9KJAGUCETqo/o4wrJXYPWcffVlJfCPR/bdf9CiLRQWwH82wbq5wdxV5QPQ6kqSZkKJQKS+Ko8jHHocrHkvuKu5XF33HwBBV9LuYLqPzr2CS1l3bIasVrB1Y5Ak9msJ3zlNiULiTolApDGy+0Lvaxo4tUVZMPBcMfgcxj8ege/fCi3bqStJ4kaJQKSxcq+Cxc/Xff9BRlbw139tX/zVeSm8/1jwvPxOZohuviqRKCkRiDRWNPcflE/6B9Vmlq0swo1r5Up2was3wZbVkafy1rQX0gBKBCKxUJ+7mysnjXDTXXzxESycFObL3mHzytqPrWkvpAGUCESaWjRJI/fKoPunyp3MkVRqSWjaC2kAJQKR5qg8WVQskFRtIaHuZ8IBnYKWxIeTqyaLLz5KVNSSpJQIRJqzcOMP1QeEv1hcrdUQvzVGJDUpEYg0d3V1JR2WV/u2SB0015BIsqveFfTh5KBLSSRKSgQiSa9aV9CGhcG4QnkyWL8gWNJTyUEiUNeQSLIL1xVUsgtmj4WslrByFuCQuT8M/qVuPJMalAhEkt3OLdS8Gc3h3/+oul/JLnj99qBON55JJeoaEkl2OQOCCeqwOnZ0KpJFya7gSiQRlAhEkl/5Jab51wXzGUXFg7EEjRsISgQiqSG7Lwz5X7huBuRfHySFIb8Nnme2AAvzX33FdJhwLp89eh4XndiFjIwMcnJymDJlStPHLwmlMQKRVBLunoPcK4NuoFV/h7Vzq1R52V6OLn6X5wfDnw5pweSPCxk5ciQAV199dVNFLQlm7sl1F2J+fr4XFBQkOgyR5LN+AUw8D0r3VBS5gxm4Ow7sKYXTJ+1gU2YX1qxZk7BQJfbMbKG754erU9eQSLrI7gsjpgfdRRnlnQHBH4JmRoYZ+2fCsF5ZrFu3LnFxSpNTIhBJJxVjCW9A/vXsLTXKqvUKHNrG6Nq1a4IClETQGIFIOgqNJcz54mA6fPBr8jvvu/R0y+4Mxo4dm8DgpKmpRSCSxs7+4X/zbf7tAJS5s7fM6Hr+3RooTjNKBCJp7oyBgwDIMKNFVhZnn312giOSpqZEIJLuPnlp3/OyvcHKaJJWlAhE0t32oqrb275KTBySMHFNBGY22Mw+NbNVZnZPmPquZjbHzD40s4/N7Nx4xiMiIjXFLRGYWSbwe+Ac4DjgSjM7rtpu9wMvuPsJwBXAH+IVj4hE0KZT1e0DOoXfT1JWPFsEfYFV7r7a3fcAzwMXVNvHgXah5+2BjXGMR0TCOaxHte28hIQhiRPP+wiOANZX2i4ETqq2z4PAW2Z2K9AGOCPcgcxsJDAS0I0uIrH2xZKq26tmBWsctOoQ/Ny/PXy1FHDIvUprGKSgRN9QdiUw0d1/Y2b9gT+bWQ93L6u8k7s/AzwDwVxDCYhTJHVVHyxe8XrwCGfRc8EMp0oGKSWeXUMbgOxK211CZZXdALwA4O7zgJZAxzjGJCLV1bWeTWW6vDQlxTMRfAB0N7NuZtaCYDB4WrV91gGDAMzsWIJEUO3PExGJq3adq25bZvj1C8rp8tKUE7euIXcvMbNbgDeBTGC8uy81s4eAAnefBvwUeNbM7iAYOB7hyTYvtkiyy70KPpwCpXshMwvOGbdvjOCLj6BgAlXWQ9ZVRSknrmME7j4DmFGt7GeVni8DTo5nDCJSh/Lpqde8G6x/XL3/f/c2+OSFfdtFnwZrG5Tvt35B5NdKUkj0YLGINAfhVjYr9/XnVbfXzoUJ5wYrn5WVwMfPg5dB5v4w4nUlgySkRCAitWt7WM2ysr3w4eSqZaW7g4FkJYKko7mGRKR2J99eaUWzOmggOSkpEYhI7bL7VqxoFiSE8utNw1x3WvRZMGYgSUWL14tI9MoHhsvvOl76MnzxSdV9MrJ001kzVNvi9RojEJHoVR9ULl5fMxGU7YX3fwtXTGna2KTB1DUkIg2XexVktqhZvnll08ciDaZEICINV34PwoFHVi1vo5likokSgYg0TnZfOKxn1bLtmzVonESUCEQk9jZ/ChOHKBkkCSUCEYmP8hvMpNlTIhCRxos0EZ1uMEsKSgQi0niRrh6SpKBEICKNF+nqoZ3fJCYeqRclAhGJjey+sF/LqmXlU1ZLs6ZEICKxU/3+gR2bdfVQElAiEJHYaXVQzTJdPdTsKRGISOxEunqo6NOmjUPqRYlARGIn0tVDW1Y1fSwSNSUCEYmd8quH2nWpWr7tSyiYmJCQpG5KBCISW9l9ofuZNcurL20pzYYSgYjEXt5VNctK9zR9HBIVJQIRib3svtC+a9WyEiWC5kqJQETio1X7qtvFhRonaKaUCEQkPqq3APZuh9dvUzJohpQIRCQ+Oh4dvlyDxs2OEoGIxMfJt0PGfjXLNWjc7CgRiEh8ZPeF696AlgdWLd+1NSHhSGRKBCISP9l9Yf92VcvcExOLRBSm3ZZ89u7dS2FhIbt27Up0KNLMtWzZki5dupCVlZXoUNJHq/ZQXG0bghlJ17wLOQOChCEJkxKJoLCwkLZt25KTk4OZJTocaabcnS1btlBYWEi3bt0SHU76qN4VVPQZ/PVHsOSv4KXBOMJhvaD3cMgfkZAQ011cu4bMbLCZfWpmq8zsngj7XGZmy8xsqZn9X0PeZ9euXXTo0EFJQGplZnTo0EEtx6ZWvSuodDd88kKQBADKSmDjIl1amkBxSwRmlgn8HjgHOA640syOq7ZPd+Be4GR3Px64vRHv1/BgJW3oc5IAnXtGv++/noxfHBJRPFsEfYFV7r7a3fcAzwMXVNvnR8Dv3f0bAHf/Ko7xiEgiRLqMNJyd38YzEokgqkRgZieb2Swz+8zMVpvZv81sdR0vOwJYX2m7MFRW2THAMWb2vpnNN7PBEd5/pJkVmFlBUVFRNCE3uczMTPLy8sjNzaV3797MnTs3pscfMWIEL730EgA//OEPWbZsWUyP35TcnVGjRnH00UfTq1cvFi1aFHa/hQsX0rNnT44++mhGjRqFh7oYvv76a84880y6d+/OmWeeyTffBAukjxs3jry8PPLy8ujRoweZmZl8/fXXTXZeEkH5ZaSDfhYkhaMGBj/zr4esNlX3DbeWgcSfu9f5AFYQdPEcAnQof9TxmkuAP1bavhb4XbV9XgdeBrKAbgSJ48DajtunTx+vbtmyZTXKmlqbNm0qns+cOdNPPfXUmB5/+PDh/uKLL8b0mLG2d+/eqPabPn26Dx482MvKynzevHnet2/fsPudeOKJPm/ePC8rK/PBgwf7jBkz3N199OjR/sgjj7i7+yOPPOJ33XVXjddOmzbNTz/99LDHbQ6fFwl58mT3B9rtezx5cqIjSllAgUf4Xo22a6jY3d9w96/cfUv5o47XbACyK213CZVVVghMc/e97v5v4DOge5QxNVtbt27loIOCtVu3bdvGoEGD6N27Nz179uTVV18FYPv27Zx33nnk5ubSo0cPpk6dCgR/BZ922mn06dOHs88+m02bNtU4/g9+8AMKCgoAOOCAAxgzZgy5ubn069ePL7/8EoCioiIuvvhiTjzxRE488UTef//9GsdZunQpffv2JS8vj169erFy5UoAJk+eTK9evcjNzeXaa68FYM2aNQwcOJBevXoxaNAg1q1bBwQtlR//+MecdNJJ3HXXXXz++ecMHjyYPn36MGDAAFasWFHjfV999VWGDRuGmdGvXz++/fbbGue5adMmtm7dSr9+/TAzhg0bxiuvvFLx+uHDhwMwfPjwivLK/vKXv3DllVfW8luSZiHcFUUaMG5y0V4+OsfMxgF/A3aXF7p7+DZ94AOgu5l1I0gAVwDVJyl/BbgSmGBmHQm6iurqcqrT5U/Pq1E2pFdnru2fw849pYyYsKBG/SV9unBpfjZfb9/Djc8trFI39b/61/meO3fuJC8vj127drFp0yZmz54NBNetv/zyy7Rr147NmzfTr18/hg4dysyZMzn88MOZPn06AMXFxezdu5dbb72VV199lU6dOjF16lTGjBnD+PHjI77v9u3b6devH2PHjuWuu+7i2Wef5f777+e2227jjjvu4JRTTmHdunWcffbZLF++vMprn3rqKW677Tauvvpq9uzZQ2lpKUuXLuXhhx9m7ty5dOzYsaJr5dZbb2X48OEMHz6c8ePHM2rUqIov4MLCQubOnUtmZiaDBg3iqaeeonv37vzrX//ipptuqvi3KLdhwways/f9jdClSxc2bNhA586dq+zTpUuXGvsAfPnllxX7HnbYYRXJr9yOHTuYOXMmv/vd7+r8vUmCleyuul26O7h6CHQpaROKNhGcFPqZX6nMgYGRXuDuJWZ2C/AmkAmMd/elZvYQQRNlWqjuLDNbBpQCo6NoaTRLrVq1YvHixQDMmzePYcOGsWTJEtyd++67j3feeYeMjAw2bNjAl19+Sc+ePfnpT3/K3XffzZAhQxgwYABLlixhyZIlnHlmsLpTaWlplS/HcFq0aMGQIUMA6NOnD7NmzQLg73//e5VxhK1bt7Jt2zYOOOCAirL+/fszduxYCgsLueiii+jevTuzZ8/m0ksvpWPHjgAcfPDBFef0t7/9DYBrr72Wu+66q+I4l156KZmZmWzbto25c+dy6aWXVtTt3l3tP3qMmVmNK4Fee+01Tj755IrYpRlr2R62fVGz/M17g59KBk0iqkTg7qc35ODuPgOYUa3sZ5WeO/CT0CNmavsLvlWLzFrrD27TIqoWQG369+/P5s2bKSoqYsaMGRQVFbFw4UKysrLIyclh165dHHPMMSxatIgZM2Zw//33M2jQIC688EKOP/545s2r2aKJJCsrq+KLMDMzk5KSEgDKysqYP38+LVu2jPjaq666ipNOOonp06dz7rnn8vTTTzfofNu0aVPxngceeGBFQozkiCOOYP36fdcRFBYWcsQRR9TYp7CwMOw+hx56KJs2baJz585s2rSJQw45pMprn3/+eXULJYt+N+1rAVS2d4daBk0o2quG2pvZo+VX7pjZb8ysfd2vTE8rVqygtLSUDh06UFxczCGHHEJWVhZz5sxh7dq1AGzcuJHWrVtzzTXXMHr0aBYtWsR3v/tdioqKKhLB3r17Wbp0aYNiOOuss3jiiScqtsN9Oa9evZrvfOc7jBo1igsuuICPP/6YgQMH8uKLL7JlS9AwK+8a+v73v8/zzz8PwJQpUxgwYECN47Vr145u3brx4osvAsGFCB999FGN/YYOHcrkyZNxd+bPn0/79u1rtHw6d+5Mu3btmD9/Pu7O5MmTueCCCypeP2nSJAAmTZpUUQ5BF9s///nPKmXSjOWPgCG/hTYdw9frvoImEW3X0HhgCXBZaPtaYAJwUTyCSkblYwQQfAFOmjSJzMxMrr76as4//3x69uxJfn4+3/ve9wD45JNPGD16NBkZGWRlZfHkk0/SokULXnrpJUaNGkVxcTElJSXcfvvtHH/88fWO5/HHH+fmm2+mV69elJSUcOqpp/LUU09V2eeFF17gz3/+M1lZWRx22GHcd999HHzwwYwZM4bTTjuNzMxMTjjhBCZOnMgTTzzBddddx7hx4+jUqRMTJkwI+75Tpkzhxhtv5OGHH2bv3r1cccUV5ObmVtnn3HPPZcaMGRx99NG0bt26yrHy8vIqktYf/vAHRowYwc6dOznnnHM455xzALjnnnu47LLL+NOf/sSRRx7JCy+8UPH6l19+mbPOOquilSJJIH8EHHocTDgnuMu4Mt1X0CTMo5gJ0MwWu3teXWVNIT8/38uvmCm3fPlyjj322KYORZKUPi/N1PoFMPn/BSuZlWvRFu4rjPgSiZ6ZLXT3/HB10V4+utPMTql0wJOBnbEITkQECG48y2pdtWzPf+B3fXVJaZxF2zV0IzApNC5gwNfAiHgFJSJpqvVBsKPa7AGbPw0Gjle9FdyRrCmrYy6qFoG7L3b3XKAX0NPdT3D3mqOAIiKN0e/myHUrpsOEc4MuJImpWlsEZnaNuz9nZj+pVg6Auz8ax9hEJN3kj4Blr8Lq2eHry/bC+7+FK6Y0aViprq4WQfmlF20jPEREYmvYy0EXUPXxgnJr3lWrIMZqbRG4+9Ohnz9vmnBERIAzfw7fOy/8JaW7ioPy697QeEGMRHtD2a/NrJ2ZZZnZ22ZWZGbXxDu4ZLF+/Xq6detWcfPVN998Q7du3VizZg0rV65kyJAhHHXUUfTp04fTTz+dd955B4CJEyfSqVMn8vLyOP7447nkkkvYsWNHIk9FpPkon756/zD3rpaVwN8faPqYUlS0l4+e5e5bgSHAGuBoYHS8gko22dnZ3HjjjdxzT7Aa5z333MPIkSM57LDDOO+88xg5ciSff/45Cxcu5IknnmD16n3z6l1++eUsXryYpUuX0qJFi4pZSEWEIBl0OyV8XWFB+HKpt2gTQXkX0nnAi+5eHKd4ms76BfDub2LW13jHHXcwf/58HnvsMd577z3uvPNOpkyZQv/+/Rk6dGjFfj169GDEiBE1Xl9SUsL27dsrpq8WkZBIK5yV7oFZahXEQrT3EbxuZisIbiK70cw6Ac1zBfA37oEvPql9n91b4csl4GVgGXBoD9i/XeT9D+sJ5/yy1kNmZWUxbtw4Bg8ezFtvvUVWVhZLly6ld+/etb5u6tSpvPfee2zatIljjjmG888/v/bYRdJNeRfRX66EHZur1i2cEIwnSKNEex/BPcD3gXx33wtsp+b6w8ljV3GQBCD4uSs2DZw33niDzp07s2TJkrD1F154IT169OCii/ZN0VTeNfTFF1/Qs2dPxo0bF5NYRFJKdl8Y+N81y0v2NH0sKaiu+wgGuvtsM7uoUlnlXf4Wr8AarI6/3IGgO2jS0KBpmdkCLv5jo68+WLx4MbNmzWL+/PmccsopXHHFFRx//PEVA8MQTIhWUFDAnXfeWeP1Zsb555/PE088UTHWICKV5I+AN+4KFq8pF67LSOqtrhbBaaGf54d5DIljXPGV3ReGT4OBY4KfjUwC7s6NN97IY489RteuXRk9ejR33nknV111Fe+//z7Tpk2r2Le2q4Lee+89jjrqqEbFIpLSqi1CRNnexMSRYuq6j+CB0M/rmiacJpTdN2bXID/77LN07dq1YmWxm266iQkTJrBgwQJef/11fvKTn3D77bdz6KGH0rZtW+6///6K15aPEZSVldGlSxcmTpwYk5hEUlJ5l26kbWmQaKeh/h/g1+7+bWj7IOCn7n5/rS+MA01DLY2lz0sS+0WnoEu3nGXA9W/qxrIoxGIa6nPKkwCAu38DnBuD2EREGs7LYPxgTTnRSNEmgkwz2798w8xaAfvXsr+ISOxlZNUs81J4PabLnqedaBPBFOBtM7vBzG4AZgGT4heWiEgYh+eGL9+8omnjSDHR3kfwK+Bh4NjQ4xfu/ut4BiYiUsMZPwfLrFkexVinRBZtiwBgOTDT3e8E3jUzTUMtIk0ruy9cPzMYJJaYiXb20R8BLwFPh4qOAF6JU0wiIpGFu0JIl5E2SrRp9WbgZGArgLuvBA6JV1DJKDMzk7y8PHJzc+nduzdz585t0HEee+wxTUUtUierY1vqI9pEsNvdKy7eNbP9gKTtlJsyZQo5OTlkZGSQk5PDlCmNX/auVatWLF68mI8++ohHHnmEe++9t0HHUSIQiUb1r5+k/TpqFqJNBP80s/uAVmZ2JvAi8Fr8woqfKVOmMHLkSNauXYu7s3btWkaOHBmTZFBu69atVaaTHjduHCeeeCK9evXigQeCaXO3b9/OeeedR25uLj169GDq1Kk8/vjjbNy4kdNPP53TTz89ZvGIpJ5qLQB33UvQCNHO2HQ38EPgE+C/gBnAH+MVVDyNGTOmxl/cO3bsYMyYMVx99dUNPu7OnTvJy8tj165dbNq0idmzg8W333rrLVauXMmCBQtwd4YOHco777xDUVERhx9+ONOnTweguLiY9u3b8+ijjzJnzhw6duzY8JMUSXU1rhLy4May62fqLuMGqLNFYGaZwHJ3f9bdL3X3S0LPk7Ittm7dunqVR6u8a2jFihXMnDmTYcOG4e689dZbvPXWW5xwwgn07t2bFStWsHLlSnr27MmsWbO4++67effdd2nfPsxyfCISXka4S0h1Y1lD1ZkI3L0U+NTMujZBPHHXtWv404hU3hD9+/dn8+bNFBUV4e7ce++9LF68mMWLF7Nq1SpuuOEGjjnmGBYtWkTPnj25//77eeihh2L2/iIp7/gLw5d/+YlWLWuAaMcIDgKWhhaun1b+iGdg8TJ27Fhat25dpax169aMHTs2Zu+xYsUKSktL6dChA2effTbjx49n27ZtAGzYsIGvvvqKjRs30rp1a6655hpGjx7NokWLAGjbti3/+c9/YhaLSEq6+FnoeVn4uvcfUzKop2jHCMIsDVQ3MxsM/BbIBP7o7mFXjTGziwnuUzjR3eO6InX5OMCYMWNYt24dXbt2ZezYsY0aH4B9YwQQrE8wadIkMjMzOeuss1i+fDn9+/cH4IADDuC5555j1apVjB49moyMDLKysnjyyScBGDlyJIMHD+bwww9nzpw5jYpJJKVd/CwsfTn8mgRzn9ASlvVQ6zTUZtYS+DFwNMFA8Z/cvSSqAwdjC58BZwKFwAfAle6+rNp+bYHpQAvglroSgaahlsbS5yWF/PVH8MkL4et6XhYkCwEaNw31JCCfIAmcA/ymHu/bF1jl7qtD9yA8T/h1jn8B/ArYVY9ji4jU3kW0tPmtpNtc1ZUIjnP3a9z9aeASYEA9jn0EsL7SdmGorIKZ9Qay3X16bQcys5FmVmBmBUVFRfUIQURS3sXPwsm31ywvi6rzQqg7EVR0vkXbJRQtM8sAHgV+Wte+7v6Mu+e7e36nTp0i7RPL8CRF6XOSojQe0Ch1JYJcM9saevwH6FX+3My21vHaDUB2pe0uobJybYEewD/MbA3QD5hmZmH7sGrTsmVLtmzZov/kUit3Z8uWLbRs2TLRoUhT+euPEh1BUqhr8fowd21E7QOgu5l1I0gAVwBXVTp2MVBx+6yZ/QO4syFXDXXp0oXCwkLUbSR1admyJV26dEl0GNJUygeSNWhcq2gvH603dy8xs1uANwkuHx3v7kvN7CGgwN1jdh9CVlYW3bp1i9XhRCQZZbaE0jDXnCz5qxJBHeKWCADcfQbBvESVy34WYd8fxDMWEUlx/X4c3ExWnZc2eSjJRsv8iEhqOPPn4a8ekjopEYhI6tDVQw2iRCAikuaUCEQk9U2OMFupAEoEIpIOVs9WMqiFEoGIpJgIX2urZ2t66giUCEQktfS8JHKd1ioIS4lARFJLbTOSAsz7fdPFkiSUCEQk9Vz8LHT8bvi6cAvZpDklAhFJTbcsiJwMpAolAhFJXbcsSHQESUGJQEQkzSkRiEj6+d+eiY6gWVEiEJEUF2ZZleJ1TR9GM6ZEICKp7eRbEx1Bs6dEICKpLdKMpFrGsoISgYikp09egAfbw7hjEh1JwikRiEh62/5l2icDJQIRSX1tDq29fvuXaT07qRKBiKS+0Z/VnQzSeKpqJQIRSQ+jP4MHi2ufkG717KaLpxlRIhCR9HLxs3W3DtKMEoGIpJ/auooePyHt1ixQIhCR9DT6s/DlX69OuwVslAhERMJ5/7FER9BklAhEJH1pvQJAiUBE0tktC6B910RHkXBKBCKS3u74BG6YlegoEkqJQEQku2/48jS5wUyJQEQkkjS52ziuicDMBpvZp2a2yszuCVP/EzNbZmYfm9nbZnZkPOMREam3NLjbOG6JwMwygd8D5wDHAVea2XHVdvsQyHf3XsBLwK/jFY+ISK0szEpmaSKeLYK+wCp3X+3ue4DngQsq7+Duc9x9R2hzPtAljvGIiET2wNdpmwzimQiOANZX2i4MlUVyA/BGHOMREandA18nOoKE2C/RAQCY2TVAPnBahPqRwEiArl11za+ISCzFs0WwAciutN0lVFaFmZ0BjAGGuvvucAdy92fcPd/d8zt16hSXYEVE0lU8E8EHQHcz62ZmLYArgGmVdzCzE4CnCZLAV3GMRUREIohbInD3EuAW4E1gOfCCuy81s4fMbGhot3HAAcCLZrbYzKZFOJyIiMRJXMcI3H0GMKNa2c8qPT8jnu8vIiJ1053FIiJ1eahjoiOIKyUCEZG6lO2FB9snOoq4USIQEYnWzw9OdARxoUQgIhItL010BHGhRCAiUtmDxYmOoMkpEYiIVPdgcVolBCUCEZE0p0QgIpLmlAhEROojBS8jVSIQEamvFEsGSgQiIg3xi0MSHUHMKBGIiETSom3kutLdKZMMlAhERCK5r7DuZJAClAhERGpzX2GiI4g7JQIRkbrUdnNZCgwcKxGIiEQjhZOBEoGISJpTIhARiYUkbhUoEYiIRCtFJ6JTIhARqY+6xgrKH0kkrovXi4ikpAeL6/6yD1ffTFsUahGIiDSVZtpSUCIQEUlzSgQiIg1x8u2JjiBmNEYgItIQZ/48+Ll8Ghw7NNiOpuun8j7NZMzA3D3RMdRLfn6+FxQUJDoMEZG61WdMIM5JwcwWunt+uDp1DYmINAcJHEhW15CISHMRKRnEubWgFoGISLzE6gs8zq0FtQhEROKpejJo6Jf6g+3j1jJQi0BEpCk9WNzwL/Q4TV8R10RgZoPN7FMzW2Vm94Sp39/Mpobq/2VmOfGMR0Sk2WjMX/cxTgZx6xoys0zg98CZQCHwgZlNc/dllXa7AfjG3Y82syuAXwGXxyumy5+eV6NsSK/OXNs/h517ShkxYUGN+kv6dOHS/Gy+3r6HG59bWKP+mn5Hcn7u4Wz8did3TF1co/5HA77DGccdyudF27jvb5/UqL91YHdO6d6RpRuLeei1ZTXq7xr8XfoceTAL137Nr2d+WqP+Z+cfx/GHt+e9lZt5YvbKGvX/c1FPjup0AH9f9iXPvru6Rv3/Xp7H4Qe24rWPNvLc/LU16p+8pg8Ht2nBiwXreWlhzSX7Jl7Xl1YtMvnzvDW8/vGmGvVT/6s/AM+88zlvL/+qSl3LrEwmXd8XgMffXsn7qzZXqT+odQueurYPAL+auYJFa7+pUt+5fUseu+IEAH7+2lKWbdxapf47ndrwyEW9ALj3bx+zumh7lfrjDm/HA+cfD8Dtz3/IpuJdVep7H3kQdw/+HgA//vNCvtmxp0r9yUd3ZNSg7gAMH7+AXXtLq9QPOvYQRp56FKDPnj57ET57DxaH/exN2TS44svZAatxdrEVzxZBX2CVu6929z3A88AF1fa5AJgUev4SMMjM4n3OIiLN2m/6/avKtoce8RK3G8rM7BJgsLv/MLR9LXCSu99SaZ8loX0KQ9ufh/bZXO1YI4GRAF27du2zdm3Nvx5ERFJSjC4pTfobytz9GXfPd/f8Tp06JTocEZGmE25wOcZXD8Xz8tENQHal7S6hsnD7FJrZfkB7YEscYxIRSU5xvKksni2CD4DuZtbNzFoAVwDTqu0zDRgeen4JMNuTbfIjEZEkF7cWgbuXmNktwJtAJjDe3Zea2UNAgbtPA/4E/NnMVgFfEyQLERFpQnG9s9jdZwAzqpX9rNLzXcCl8YxBRERqlxSDxSIiEj9KBCIiaU6JQEQkzSXdCmVmVgQ09I6yjsDmOvdKLTrn9KBzTg+NOecj3T3sjVhJlwgaw8wKIt1Zl6p0zulB55we4nXO6hoSEUlzSgQiImku3RLBM4kOIAF0zulB55we4nLOaTVGICIiNaVbi0BERKpRIhARSXMpmQjSca3kKM75J2a2zMw+NrO3zezIRMQZS3Wdc6X9LjYzN7Okv9QwmnM2s8tCv+ulZvZ/TR1jrEXx2e5qZnPM7MPQ5/vcRMQZK2Y23sy+Ci3cFa7ezOzx0L/Hx2bWu9Fv6u4p9SCY6fRz4DtAC+Aj4Lhq+9wEPBV6fgUwNdFxN8E5nw60Dj2/MR3OObRfW+AdYD6Qn+i4m+D33B34EDgotH1IouNugnN+Brgx9Pw4YE2i427kOZ8K9AaWRKg/F3iDYCnjfsC/GvueqdgiSMe1kus8Z3ef4+47QpvzCRYKSmbR/J4BfgH8CtgVpi7ZRHPOPwJ+7+7fALj7VyS3aM7ZgXah5+2BjU0YX8y5+zsE0/JHcgEw2QPzgQPNrHNj3jMVE8ERwPpK24WhsrD7uHsJUAx0aJLo4iOac67sBoK/KJJZneccajJnu/v0pgwsjqL5PR8DHGNm75vZfDMb3GTRxUc05/wgcI2ZFRJMe39r04SWMPX9/16nuK5HIM2PmV0D5AOnJTqWeDKzDOBRYESCQ2lq+xF0D/2AoNX3jpn1dPdvExlUnF0JTHT335hZf4LFrnq4e1miA0sWqdgiqM9ayaTIWsnRnDNmdgYwBhjq7rubKLZ4qeuc2wI9gH+Y2RqCvtRpST5gHM3vuRCY5u573f3fwGcEiSFZRXPONwAvALj7PKAlweRsqSqq/+/1kYqJIB3XSq7znM3sBOBpgiSQ7P3GUMc5u3uxu3d09xx3zyEYFxnq7gWJCTcmovlsv0LQGsDMOhJ0Fa1uwhhjLZpzXgcMAjCzYwkSQVGTRtm0pgHDQlcP9QOK3X1TYw6Ycl1DnoZrJUd5zuOAA4AXQ+Pi69x9aMKCbqQozzmlRHnObwJnmdkyoBQY7e5J29qN8px/CjxrZncQDByPSOY/7MzsLwTJvGNo3OMBIAvA3Z8iGAc5F1gF7ACua/R7JvG/l4iIxEAqdg2JiEg9KBGIiKQ5JQIRkTSnRCAikuaUCERE0pwSgUgYZlZqZovNbImZvWZmB8b4+GtC1/ljZttieWyR+lIiEAlvp7vnuXsPgntNbk50QCLxokQgUrd5hCb1MrOjzGymmS00s3fN7Huh8kPN7GUz+yj0+H6o/JXQvkvNbGQCz0EkopS7s1gklswsk2D6gj+Fip4BfuzuK83sJOAPwEDgceCf7n5h6DUHhPa/3t2/NrNWwAdm9tdkvtNXUpMSgUh4rcxsMUFLYDkwy8wOAL7Pvmk6APYP/RwIDANw91KCqc0BRpnZhaHn2QQTwCkRSLOiRCAS3k53zzOz1gTz3NwMTAS+dfe8aA5gZj8AzgD6u/sOM/sHwYRoIs2KxghEahFa1W0UwcRmO4B/m9mlULF2bG5o17cJlgDFzDLNrD3B9ObfhJLA9wimwhZpdpQIROrg7h8CHxMsgHI1cIOZfQQsZd+yibcBp5vZJ8BCgrVzZwL7mdly4JcEU2GLNDuafVREJM2pRSAikuaUCERE0pwSgYhImlMiEBFJc0oEIiJpTolARCTNKRGIiKS5/w/icyfVGTU2HgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "x = pickle.load(open('model_f1.pkl', 'rb'))\n",
    "# x.fit(X_train_sm, y_train_sm)\n",
    "best_thres, best_f1 = best_f1_pr_auc(x,'XGB',X_test,y_test)\n",
    "# best_pred_prob = x.predict_proba(X_test)\n",
    "y_pred = (x.predict_proba(X_test)[:,1] >= best_thres).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23494    20]\n",
      " [   60   114]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     23514\n",
      "         1.0       0.80      0.70      0.75       174\n",
      "\n",
      "    accuracy                           1.00     23688\n",
      "   macro avg       0.90      0.85      0.87     23688\n",
      "weighted avg       1.00      1.00      1.00     23688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md = XGBClassifier(n_estimators = 500)\n",
    "md.fit(X_train_sm,y_train_sm)\n",
    "pr = md.predict(X_test)\n",
    "print(classification_report(y_test,pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold = 0.5131067633628845 and best F-Score 0.748 achieved for XGB\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_thres, best_f1 = best_f1_pr_auc(md,'XGB',X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (md.predict_proba(X_test)[:,1] >= 0.1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     23514\n",
      "         1.0       0.60      0.80      0.68       174\n",
      "\n",
      "    accuracy                           0.99     23688\n",
      "   macro avg       0.80      0.90      0.84     23688\n",
      "weighted avg       1.00      0.99      0.99     23688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
